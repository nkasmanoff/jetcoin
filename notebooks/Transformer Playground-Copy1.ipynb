{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots to discover when using the transformer decoder model on non-text data. A running list of things to figure out include:\n",
    "\n",
    "- input non text?\n",
    "- no encoder ?\n",
    "- causal prediction of prices and/or pct_change at end of sequence?\n",
    "\n",
    "- positional encoding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Largely copied from https://github.com/tunz/transformer-pytorch/blob/master/model/transformer.py\n",
    "\n",
    "Idea is to use just the transformer decoder architecture to predict the pct_change of the coming day.\n",
    "\n",
    "Depending on model may need to re-shape the data used.\n",
    "\n",
    "Note that decoder initially used for causal modeling, and now simply predicting a property from the last element in the array,\n",
    "based on previous days.\n",
    "\"\"\"\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def initialize_weight(x):\n",
    "    nn.init.xavier_uniform_(x.weight)\n",
    "    if x.bias is not None:\n",
    "        nn.init.constant_(x.bias, 0)\n",
    "\n",
    "\n",
    "\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, hidden_size, filter_size, dropout_rate,output_size=None):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(hidden_size, filter_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        if output_size:\n",
    "            self.layer2 = nn.Linear(filter_size, output_size)\n",
    "        else:\n",
    "            self.layer2 = nn.Linear(filter_size, hidden_size)\n",
    "\n",
    "        initialize_weight(self.layer1)\n",
    "        initialize_weight(self.layer2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, dropout_rate, head_size=2):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.head_size = head_size\n",
    "\n",
    "        self.att_size = att_size = hidden_size // head_size\n",
    "        self.scale = att_size ** -0.5\n",
    "\n",
    "        self.linear_q = nn.Linear(hidden_size, head_size * att_size, bias=False)\n",
    "        self.linear_k = nn.Linear(hidden_size, head_size * att_size, bias=False)\n",
    "        self.linear_v = nn.Linear(hidden_size, head_size * att_size, bias=False)\n",
    "        initialize_weight(self.linear_q)\n",
    "        initialize_weight(self.linear_k)\n",
    "        initialize_weight(self.linear_v)\n",
    "\n",
    "        self.att_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.output_layer = nn.Linear(head_size * att_size, hidden_size,\n",
    "                                      bias=False)\n",
    "        initialize_weight(self.output_layer)\n",
    "\n",
    "    def forward(self, q, k, v, mask, cache=None):\n",
    "        orig_q_size = q.size()\n",
    "\n",
    "        d_k = self.att_size\n",
    "        d_v = self.att_size\n",
    "        batch_size = q.size(0)\n",
    "\n",
    "        # head_i = Attention(Q(W^Q)_i, K(W^K)_i, V(W^V)_i)\n",
    "        q = self.linear_q(q).view(batch_size, -1, self.head_size, d_k)\n",
    "        if cache is not None and 'encdec_k' in cache:\n",
    "            k, v = cache['encdec_k'], cache['encdec_v']\n",
    "        else:\n",
    "            k = self.linear_k(k).view(batch_size, -1, self.head_size, d_k)\n",
    "            v = self.linear_v(v).view(batch_size, -1, self.head_size, d_v)\n",
    "\n",
    "            if cache is not None:\n",
    "                cache['encdec_k'], cache['encdec_v'] = k, v\n",
    "\n",
    "        q = q.transpose(1, 2)                  # [b, h, q_len, d_k]\n",
    "        v = v.transpose(1, 2)                  # [b, h, v_len, d_v]\n",
    "        k = k.transpose(1, 2).transpose(2, 3)  # [b, h, d_k, k_len]\n",
    "\n",
    "        # Scaled Dot-Product Attention.\n",
    "        # Attention(Q, K, V) = softmax((QK^T)/sqrt(d_k))V\n",
    "        q.mul_(self.scale)\n",
    "        x = torch.matmul(q, k)  # [b, h, q_len, k_len]\n",
    "        x.masked_fill_(mask.unsqueeze(1), -1e9)\n",
    "        x = torch.softmax(x, dim=3)\n",
    "        x = self.att_dropout(x)\n",
    "        x = x.matmul(v)  # [b, h, q_len, attn]\n",
    "\n",
    "        x = x.transpose(1, 2).contiguous()  # [b, q_len, h, attn]\n",
    "        x = x.view(batch_size, -1, self.head_size * d_v)\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        assert x.size() == orig_q_size\n",
    "        return x\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_size, filter_size, dropout_rate):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.self_attention_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "        self.self_attention = MultiHeadAttention(hidden_size, dropout_rate)\n",
    "        self.self_attention_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.ffn_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "        self.ffn = FeedForwardNetwork(hidden_size, filter_size, dropout_rate)\n",
    "        self.ffn_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, mask):  # pylint: disable=arguments-differ\n",
    "        y = self.self_attention_norm(x)\n",
    "        y = self.self_attention(y, y, y, mask)\n",
    "        y = self.self_attention_dropout(y)\n",
    "        x = x + y\n",
    "\n",
    "        y = self.ffn_norm(x)\n",
    "        y = self.ffn(y)\n",
    "        y = self.ffn_dropout(y)\n",
    "        x = x + y\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_size, filter_size, dropout_rate):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.self_attention_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "        self.self_attention = MultiHeadAttention(hidden_size, dropout_rate)\n",
    "        self.self_attention_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.enc_dec_attention_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "        self.enc_dec_attention = MultiHeadAttention(hidden_size, dropout_rate)\n",
    "        self.enc_dec_attention_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.ffn_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "        self.ffn = FeedForwardNetwork(hidden_size, filter_size, dropout_rate)\n",
    "        self.ffn_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, enc_output, self_mask, i_mask, cache):\n",
    "        y = self.self_attention_norm(x)\n",
    "        y = self.self_attention(y, y, y, self_mask)\n",
    "        y = self.self_attention_dropout(y)\n",
    "        x = x + y\n",
    "\n",
    "        if enc_output is not None:\n",
    "            y = self.enc_dec_attention_norm(x)\n",
    "            y = self.enc_dec_attention(y, enc_output, enc_output, i_mask,\n",
    "                                       cache)\n",
    "            y = self.enc_dec_attention_dropout(y)\n",
    "            x = x + y\n",
    "\n",
    "        y = self.ffn_norm(x)\n",
    "        y = self.ffn(y)\n",
    "        y = self.ffn_dropout(y)\n",
    "        x = x + y\n",
    "        return x\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_size, filter_size, dropout_rate, n_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        encoders = [EncoderLayer(hidden_size, filter_size, dropout_rate)\n",
    "                    for _ in range(n_layers)]\n",
    "        self.layers = nn.ModuleList(encoders)\n",
    "\n",
    "        self.last_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "\n",
    "    def forward(self, inputs, mask):\n",
    "        encoder_output = inputs\n",
    "        for enc_layer in self.layers:\n",
    "            encoder_output = enc_layer(encoder_output, mask)\n",
    "        return self.last_norm(encoder_output)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, filter_size, dropout_rate, n_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        decoders = [DecoderLayer(hidden_size, filter_size, dropout_rate)\n",
    "                    for _ in range(n_layers)]\n",
    "        self.layers = nn.ModuleList(decoders)\n",
    "\n",
    "        self.last_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "\n",
    "    def forward(self, targets, enc_output, i_mask, t_self_mask, cache):\n",
    "        decoder_output = targets\n",
    "        for i, dec_layer in enumerate(self.layers):\n",
    "            layer_cache = None\n",
    "            if cache is not None:\n",
    "                if i not in cache:\n",
    "                    cache[i] = {}\n",
    "                layer_cache = cache[i]\n",
    "            decoder_output = dec_layer(decoder_output, enc_output,\n",
    "                                       t_self_mask, i_mask, layer_cache)\n",
    "        return self.last_norm(decoder_output)\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, i_vocab_size, t_vocab_size, #input and target vocab size. Not needed. \n",
    "                 n_layers=6,\n",
    "                 hidden_size=512,\n",
    "                 filter_size=2048,\n",
    "                 dropout_rate=0.1,\n",
    "                 share_target_embedding=True,\n",
    "                 has_inputs=True,\n",
    "                 src_pad_idx=None,\n",
    "                 trg_pad_idx=None):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.emb_scale = hidden_size ** 0.5\n",
    "        self.has_inputs = has_inputs\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "\n",
    "        self.t_vocab_embedding = nn.Embedding(t_vocab_size, hidden_size)\n",
    "        nn.init.normal_(self.t_vocab_embedding.weight, mean=0,\n",
    "                        std=hidden_size**-0.5)\n",
    "        self.t_emb_dropout = nn.Dropout(dropout_rate)\n",
    "        self.decoder = Decoder(hidden_size, filter_size,\n",
    "                               dropout_rate, n_layers)\n",
    "\n",
    "        if has_inputs:\n",
    "            if not share_target_embedding:\n",
    "                self.i_vocab_embedding = nn.Embedding(i_vocab_size,\n",
    "                                                      hidden_size)\n",
    "                nn.init.normal_(self.i_vocab_embedding.weight, mean=0,\n",
    "                                std=hidden_size**-0.5)\n",
    "            else:\n",
    "                self.i_vocab_embedding = self.t_vocab_embedding\n",
    "\n",
    "            self.i_emb_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "            self.encoder = Encoder(hidden_size, filter_size,\n",
    "                                   dropout_rate, n_layers)\n",
    "\n",
    "        # For positional encoding\n",
    "        num_timescales = self.hidden_size // 2\n",
    "        max_timescale = 10000.0\n",
    "        min_timescale = 1.0\n",
    "        log_timescale_increment = (\n",
    "            math.log(float(max_timescale) / float(min_timescale)) /\n",
    "            max(num_timescales - 1, 1))\n",
    "        inv_timescales = min_timescale * torch.exp(\n",
    "            torch.arange(num_timescales, dtype=torch.float32) *\n",
    "            -log_timescale_increment)\n",
    "        self.register_buffer('inv_timescales', inv_timescales)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        enc_output, i_mask = None, None\n",
    "        if self.has_inputs:\n",
    "            i_mask = utils.create_pad_mask(inputs, self.src_pad_idx)\n",
    "            enc_output = self.encode(inputs, i_mask)\n",
    "\n",
    "        t_mask = utils.create_pad_mask(targets, self.trg_pad_idx)\n",
    "        target_size = targets.size()[1]\n",
    "        t_self_mask = utils.create_trg_self_mask(target_size,\n",
    "                                                 device=targets.device)\n",
    "        return self.decode(targets, enc_output, i_mask, t_self_mask, t_mask)\n",
    "\n",
    "    def encode(self, inputs, i_mask):\n",
    "        # Input embedding\n",
    "        input_embedded = self.i_vocab_embedding(inputs)\n",
    "        input_embedded.masked_fill_(i_mask.squeeze(1).unsqueeze(-1), 0)\n",
    "        input_embedded *= self.emb_scale\n",
    "        input_embedded += self.get_position_encoding(inputs)\n",
    "        input_embedded = self.i_emb_dropout(input_embedded)\n",
    "\n",
    "        return self.encoder(input_embedded, i_mask)\n",
    "\n",
    "    def decode(self, targets, enc_output, i_mask, t_self_mask, t_mask,\n",
    "               cache=None):\n",
    "        # target embedding\n",
    "        target_embedded = self.t_vocab_embedding(targets)\n",
    "        target_embedded.masked_fill_(t_mask.squeeze(1).unsqueeze(-1), 0)\n",
    "\n",
    "        # Shifting\n",
    "        target_embedded = target_embedded[:, :-1]\n",
    "        target_embedded = F.pad(target_embedded, (0, 0, 1, 0))\n",
    "\n",
    "        target_embedded *= self.emb_scale\n",
    "        target_embedded += self.get_position_encoding(targets)\n",
    "        target_embedded = self.t_emb_dropout(target_embedded)\n",
    "\n",
    "        # decoder\n",
    "        decoder_output = self.decoder(target_embedded, enc_output, i_mask,\n",
    "                                      t_self_mask, cache)\n",
    "        # linear\n",
    "        output = torch.matmul(decoder_output,\n",
    "                              self.t_vocab_embedding.weight.transpose(0, 1))\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_position_encoding(self, x):\n",
    "        max_length = x.size()[1]\n",
    "        position = torch.arange(max_length, dtype=torch.float32,\n",
    "                                device=x.device)\n",
    "        scaled_time = position.unsqueeze(1) * self.inv_timescales.unsqueeze(0)\n",
    "        signal = torch.cat([torch.sin(scaled_time), torch.cos(scaled_time)],\n",
    "                           dim=1)\n",
    "        signal = F.pad(signal, (0, 0, 0, self.hidden_size % 2))\n",
    "        signal = signal.view(1, max_length, self.hidden_size)\n",
    "        return signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode(self, targets, enc_output, i_mask, t_self_mask, t_mask,\n",
    "           cache=None):\n",
    "    # target embedding\n",
    "#    target_embedded = self.t_vocab_embedding(targets)\n",
    "#    target_embedded.masked_fill_(t_mask.squeeze(1).unsqueeze(-1), 0)\n",
    "\n",
    "    # Shifting\n",
    "    target_embedded = target_embedded[:, :-1]\n",
    "    target_embedded = F.pad(target_embedded, (0, 0, 1, 0))\n",
    "\n",
    "    target_embedded *= self.emb_scale\n",
    "    target_embedded += self.get_position_encoding(targets)\n",
    "    target_embedded = self.t_emb_dropout(target_embedded)\n",
    "\n",
    "    # decoder\n",
    "    decoder_output = self.decoder(target_embedded, enc_output, i_mask,\n",
    "                                  t_self_mask, cache)\n",
    "    # linear\n",
    "    output = torch.matmul(decoder_output,\n",
    "                          self.t_vocab_embedding.weight.transpose(0, 1))\n",
    "\n",
    "    return output\n",
    "\n",
    "def get_position_encoding(self, x):\n",
    "    max_length = x.size()[1]\n",
    "    position = torch.arange(max_length, dtype=torch.float32,\n",
    "                            device=x.device)\n",
    "    scaled_time = position.unsqueeze(1) * self.inv_timescales.unsqueeze(0)\n",
    "    signal = torch.cat([torch.sin(scaled_time), torch.cos(scaled_time)],\n",
    "                       dim=1)\n",
    "    signal = F.pad(signal, (0, 0, 0, self.hidden_size % 2))\n",
    "    signal = signal.view(1, max_length, self.hidden_size)\n",
    "    return signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_size, filter_size, dropout_rate):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.self_attention_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "        self.self_attention = MultiHeadAttention(hidden_size, dropout_rate)\n",
    "        self.self_attention_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "       # self.enc_dec_attention_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "       # self.enc_dec_attention = MultiHeadAttention(hidden_size, dropout_rate)\n",
    "       # self.enc_dec_attention_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.ffn_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "        self.ffn = FeedForwardNetwork(hidden_size, filter_size, dropout_rate)\n",
    "        self.ffn_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, self_mask, cache):\n",
    "        y = self.self_attention_norm(x)\n",
    "        y = self.self_attention(y, y, y, self_mask)\n",
    "        y = self.self_attention_dropout(y)\n",
    "        x = x + y\n",
    "\n",
    "        y = self.ffn_norm(x)\n",
    "        y = self.ffn(y)\n",
    "        y = self.ffn_dropout(y)\n",
    "        x = x + y\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, filter_size, dropout_rate, n_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        decoders = [DecoderLayer(hidden_size, filter_size, dropout_rate)\n",
    "                    for _ in range(n_layers)]\n",
    "        self.layers = nn.ModuleList(decoders)\n",
    "\n",
    "        self.last_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "\n",
    "    def forward(self, targets, t_self_mask, cache):\n",
    "        decoder_output = targets\n",
    "        for i, dec_layer in enumerate(self.layers):\n",
    "            layer_cache = None\n",
    "            if cache is not None:\n",
    "                if i not in cache:\n",
    "                    cache[i] = {}\n",
    "                layer_cache = cache[i]\n",
    "            decoder_output = dec_layer(decoder_output,\n",
    "                                       t_self_mask, layer_cache)\n",
    "        return self.last_norm(decoder_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Decoder(hidden_size=8,filter_size=64,dropout_rate=.5,n_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_embedded = torch.randn(1,8) # convert to embedding, which is going to be numerical? \n",
    "#target_embedded += self.get_position_encoding(targets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_self_mask = torch.ones(8,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-14dc79089d00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets_embedded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_self_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-502e12aa9233>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, targets, t_self_mask, cache)\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mlayer_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             decoder_output = dec_layer(decoder_output,\n\u001b[0m\u001b[1;32m     49\u001b[0m                                        t_self_mask, layer_cache)\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-502e12aa9233>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, self_mask, cache)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attention_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attention_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-f2846e395915>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, q, k, v, mask, cache)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0morig_q_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model(targets_embedded,t_self_mask,cache=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step I: From Data to Positionally Encoded Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from dataloaders import create_dataloaders\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train_loader, _, _ = create_dataloaders(prior_years=3,crypto='btc',values='usd',batch_size=8,buy_thresh=3,labels_to_load=['pct_change'],window=7)\n",
    "\n",
    "for batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, _, _ = create_dataloaders(prior_years=3,crypto='btc',values='usd',batch_size=8,buy_thresh=3,labels_to_load=['pct_change'],window=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fac55c1d640>]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(batch[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 6\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For positional encoding\n",
    "num_timescales = hidden_size // 2\n",
    "max_timescale = 1000000.0\n",
    "min_timescale = 1.0\n",
    "log_timescale_increment = (\n",
    "    math.log(float(max_timescale) / float(min_timescale)) /\n",
    "    max(num_timescales - 1, 1))\n",
    "inv_timescales = min_timescale * torch.exp(\n",
    "    torch.arange(num_timescales, dtype=torch.float32) *\n",
    "    -log_timescale_increment)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_position_encoding(x):\n",
    "    max_length = x.shape[0]\n",
    "    position = torch.arange(max_length, dtype=torch.float32,\n",
    "                            device=x.device)\n",
    "    scaled_time = position.unsqueeze(1) * inv_timescales.unsqueeze(0)\n",
    "    signal = torch.cat([torch.sin(scaled_time), torch.cos(scaled_time)],\n",
    "                       dim=1)\n",
    "    signal = F.pad(signal, (0, 0, 0, hidden_size % 2))\n",
    "    signal = signal.view(1, max_length, hidden_size)\n",
    "    return signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = batch[0][-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fac55ffbc10>]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "           1.0000e+00],\n",
       "         [ 8.4147e-01,  1.0000e-03,  1.0000e-06,  5.4030e-01,  1.0000e+00,\n",
       "           1.0000e+00],\n",
       "         [ 9.0930e-01,  2.0000e-03,  2.0000e-06, -4.1615e-01,  1.0000e+00,\n",
       "           1.0000e+00],\n",
       "         [ 1.4112e-01,  3.0000e-03,  3.0000e-06, -9.8999e-01,  1.0000e+00,\n",
       "           1.0000e+00],\n",
       "         [-7.5680e-01,  4.0000e-03,  4.0000e-06, -6.5364e-01,  9.9999e-01,\n",
       "           1.0000e+00],\n",
       "         [-9.5892e-01,  5.0000e-03,  5.0000e-06,  2.8366e-01,  9.9999e-01,\n",
       "           1.0000e+00],\n",
       "         [-2.7942e-01,  6.0000e-03,  6.0000e-06,  9.6017e-01,  9.9998e-01,\n",
       "           1.0000e+00]]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_position_encoding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "          1.0000e+00],\n",
       "        [ 8.4147e-01,  1.0000e-03,  1.0000e-06,  5.4030e-01,  1.0000e+00,\n",
       "          1.0000e+00],\n",
       "        [ 9.0930e-01,  2.0000e-03,  2.0000e-06, -4.1615e-01,  1.0000e+00,\n",
       "          1.0000e+00],\n",
       "        [ 1.4112e-01,  3.0000e-03,  3.0000e-06, -9.8999e-01,  1.0000e+00,\n",
       "          1.0000e+00],\n",
       "        [-7.5680e-01,  4.0000e-03,  4.0000e-06, -6.5364e-01,  9.9999e-01,\n",
       "          1.0000e+00],\n",
       "        [-9.5892e-01,  5.0000e-03,  5.0000e-06,  2.8366e-01,  9.9999e-01,\n",
       "          1.0000e+00],\n",
       "        [-2.7942e-01,  6.0000e-03,  6.0000e-06,  9.6017e-01,  9.9998e-01,\n",
       "          1.0000e+00]])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_position_encoding(batch[0][-1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "          1.0000e+00],\n",
       "        [ 8.4147e-01,  1.0000e-03,  1.0000e-06,  5.4030e-01,  1.0000e+00,\n",
       "          1.0000e+00],\n",
       "        [ 9.0930e-01,  2.0000e-03,  2.0000e-06, -4.1615e-01,  1.0000e+00,\n",
       "          1.0000e+00],\n",
       "        [ 1.4112e-01,  3.0000e-03,  3.0000e-06, -9.8999e-01,  1.0000e+00,\n",
       "          1.0000e+00],\n",
       "        [-7.5680e-01,  4.0000e-03,  4.0000e-06, -6.5364e-01,  9.9999e-01,\n",
       "          1.0000e+00],\n",
       "        [-9.5892e-01,  5.0000e-03,  5.0000e-06,  2.8366e-01,  9.9999e-01,\n",
       "          1.0000e+00],\n",
       "        [-2.7942e-01,  6.0000e-03,  6.0000e-06,  9.6017e-01,  9.9998e-01,\n",
       "          1.0000e+00]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_position_encoding(batch[0][0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fac4843e700>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(get_position_encoding(batch[0][0])[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fac55effd90>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(get_position_encoding(batch[0][-1])[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Embedding,Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Linear(in_features=1,out_features=hidden_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = batch[0][0].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = embedding_layer(x).unsqueeze(0)\n",
    "x += get_position_encoding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9107, -1.1920,  1.4491,  0.0609,  1.4767,  0.5452],\n",
       "         [ 0.7208, -1.0516,  1.1178,  0.2788,  1.3764,  0.6726],\n",
       "         [ 0.6751, -1.0177,  1.0379,  0.3313,  1.3522,  0.7033],\n",
       "         [ 0.3319, -0.7640,  0.4391,  0.7251,  1.1709,  0.9334],\n",
       "         [ 0.0282, -0.5394, -0.0908,  1.0735,  1.0105,  1.1371],\n",
       "         [-0.1860, -0.3810, -0.4647,  1.3194,  0.8972,  1.2808],\n",
       "         [-0.4654, -0.1744, -0.9522,  1.6399,  0.7496,  1.4681]]],\n",
       "       grad_fn=<AsStridedBackward>)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_size, filter_size, dropout_rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.self_attention_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "        self.self_attention = MultiHeadAttention(hidden_size, dropout_rate)\n",
    "        self.self_attention_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "       # self.enc_dec_attention_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "        #self.enc_dec_attention = MultiHeadAttention(hidden_size, dropout_rate)\n",
    "        #self.enc_dec_attention_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.ffn_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "        self.ffn = FeedForwardNetwork(hidden_size, filter_size, dropout_rate)\n",
    "        self.ffn_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, self_mask):\n",
    "        y = self.self_attention_norm(x)\n",
    "        y = self.self_attention(y, y, y, self_mask)\n",
    "        y = self.self_attention_dropout(y)\n",
    "        x = x + y\n",
    "\n",
    "       # if enc_output is not None:\n",
    "       #     y = self.enc_dec_attention_norm(x)\n",
    "        #    y = self.enc_dec_attention(y, enc_output, enc_output, i_mask,\n",
    "                                   #    cache)\n",
    "          #  y = self.enc_dec_attention_dropout(y)\n",
    "        #   x = x + y\n",
    "\n",
    "        y = self.ffn_norm(x)\n",
    "        y = self.ffn(y)\n",
    "        y = self.ffn_dropout(y)\n",
    "        x = x + y\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, filter_size, dropout_rate, n_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        decoders = [DecoderLayer(hidden_size, filter_size, dropout_rate)\n",
    "                    for _ in range(n_layers)]\n",
    "        self.layers = nn.ModuleList(decoders)\n",
    "\n",
    "        self.last_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "\n",
    "    def forward(self, x, self_mask):\n",
    "        decoder_output = x\n",
    "        for i, dec_layer in enumerate(self.layers):\n",
    "            decoder_output = dec_layer(decoder_output,\n",
    "                                       self_mask)\n",
    "        return self.last_norm(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_layer = DecoderLayer(hidden_size, filter_size=3)\n",
    "\n",
    "decoder = Decoder(hidden_size=6,filter_size=3,dropout_rate=.1,n_layers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.ones(1,7)\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = decoder.forward(x=x,self_mask=mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 6])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (layers): ModuleList(\n",
       "    (0): DecoderLayer(\n",
       "      (self_attention_norm): LayerNorm((6,), eps=1e-06, elementwise_affine=True)\n",
       "      (self_attention): MultiHeadAttention(\n",
       "        (linear_q): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (linear_k): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (linear_v): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (output_layer): Linear(in_features=6, out_features=6, bias=False)\n",
       "      )\n",
       "      (self_attention_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ffn_norm): LayerNorm((6,), eps=1e-06, elementwise_affine=True)\n",
       "      (ffn): FeedForwardNetwork(\n",
       "        (layer1): Linear(in_features=6, out_features=3, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer2): Linear(in_features=3, out_features=6, bias=True)\n",
       "      )\n",
       "      (ffn_dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): DecoderLayer(\n",
       "      (self_attention_norm): LayerNorm((6,), eps=1e-06, elementwise_affine=True)\n",
       "      (self_attention): MultiHeadAttention(\n",
       "        (linear_q): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (linear_k): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (linear_v): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (output_layer): Linear(in_features=6, out_features=6, bias=False)\n",
       "      )\n",
       "      (self_attention_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ffn_norm): LayerNorm((6,), eps=1e-06, elementwise_affine=True)\n",
       "      (ffn): FeedForwardNetwork(\n",
       "        (layer1): Linear(in_features=6, out_features=3, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer2): Linear(in_features=3, out_features=6, bias=True)\n",
       "      )\n",
       "      (ffn_dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): DecoderLayer(\n",
       "      (self_attention_norm): LayerNorm((6,), eps=1e-06, elementwise_affine=True)\n",
       "      (self_attention): MultiHeadAttention(\n",
       "        (linear_q): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (linear_k): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (linear_v): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (output_layer): Linear(in_features=6, out_features=6, bias=False)\n",
       "      )\n",
       "      (self_attention_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ffn_norm): LayerNorm((6,), eps=1e-06, elementwise_affine=True)\n",
       "      (ffn): FeedForwardNetwork(\n",
       "        (layer1): Linear(in_features=6, out_features=3, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer2): Linear(in_features=3, out_features=6, bias=True)\n",
       "      )\n",
       "      (ffn_dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): DecoderLayer(\n",
       "      (self_attention_norm): LayerNorm((6,), eps=1e-06, elementwise_affine=True)\n",
       "      (self_attention): MultiHeadAttention(\n",
       "        (linear_q): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (linear_k): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (linear_v): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (output_layer): Linear(in_features=6, out_features=6, bias=False)\n",
       "      )\n",
       "      (self_attention_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ffn_norm): LayerNorm((6,), eps=1e-06, elementwise_affine=True)\n",
       "      (ffn): FeedForwardNetwork(\n",
       "        (layer1): Linear(in_features=6, out_features=3, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer2): Linear(in_features=3, out_features=6, bias=True)\n",
       "      )\n",
       "      (ffn_dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): DecoderLayer(\n",
       "      (self_attention_norm): LayerNorm((6,), eps=1e-06, elementwise_affine=True)\n",
       "      (self_attention): MultiHeadAttention(\n",
       "        (linear_q): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (linear_k): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (linear_v): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (output_layer): Linear(in_features=6, out_features=6, bias=False)\n",
       "      )\n",
       "      (self_attention_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ffn_norm): LayerNorm((6,), eps=1e-06, elementwise_affine=True)\n",
       "      (ffn): FeedForwardNetwork(\n",
       "        (layer1): Linear(in_features=6, out_features=3, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer2): Linear(in_features=3, out_features=6, bias=True)\n",
       "      )\n",
       "      (ffn_dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): DecoderLayer(\n",
       "      (self_attention_norm): LayerNorm((6,), eps=1e-06, elementwise_affine=True)\n",
       "      (self_attention): MultiHeadAttention(\n",
       "        (linear_q): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (linear_k): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (linear_v): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (output_layer): Linear(in_features=6, out_features=6, bias=False)\n",
       "      )\n",
       "      (self_attention_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ffn_norm): LayerNorm((6,), eps=1e-06, elementwise_affine=True)\n",
       "      (ffn): FeedForwardNetwork(\n",
       "        (layer1): Linear(in_features=6, out_features=3, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer2): Linear(in_features=3, out_features=6, bias=True)\n",
       "      )\n",
       "      (ffn_dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): DecoderLayer(\n",
       "      (self_attention_norm): LayerNorm((6,), eps=1e-06, elementwise_affine=True)\n",
       "      (self_attention): MultiHeadAttention(\n",
       "        (linear_q): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (linear_k): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (linear_v): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (output_layer): Linear(in_features=6, out_features=6, bias=False)\n",
       "      )\n",
       "      (self_attention_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ffn_norm): LayerNorm((6,), eps=1e-06, elementwise_affine=True)\n",
       "      (ffn): FeedForwardNetwork(\n",
       "        (layer1): Linear(in_features=6, out_features=3, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer2): Linear(in_features=3, out_features=6, bias=True)\n",
       "      )\n",
       "      (ffn_dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): DecoderLayer(\n",
       "      (self_attention_norm): LayerNorm((6,), eps=1e-06, elementwise_affine=True)\n",
       "      (self_attention): MultiHeadAttention(\n",
       "        (linear_q): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (linear_k): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (linear_v): Linear(in_features=6, out_features=6, bias=False)\n",
       "        (att_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (output_layer): Linear(in_features=6, out_features=6, bias=False)\n",
       "      )\n",
       "      (self_attention_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (ffn_norm): LayerNorm((6,), eps=1e-06, elementwise_affine=True)\n",
       "      (ffn): FeedForwardNetwork(\n",
       "        (layer1): Linear(in_features=6, out_features=3, bias=True)\n",
       "        (relu): ReLU()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer2): Linear(in_features=3, out_features=6, bias=True)\n",
       "      )\n",
       "      (ffn_dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (last_norm): LayerNorm((6,), eps=1e-06, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1716"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " sum(p.numel() for p in decoder.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together...\n",
    "\n",
    "pasting the only used functions/classes and then doing a toy forward pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def initialize_weight(x):\n",
    "    nn.init.xavier_uniform_(x.weight)\n",
    "    if x.bias is not None:\n",
    "        nn.init.constant_(x.bias, 0)\n",
    "\n",
    "\n",
    "\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, hidden_size, filter_size, dropout_rate,output_size=None):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(hidden_size, filter_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        if output_size:\n",
    "            self.layer2 = nn.Linear(filter_size, output_size)\n",
    "        else:\n",
    "            self.layer2 = nn.Linear(filter_size, hidden_size)\n",
    "\n",
    "        initialize_weight(self.layer1)\n",
    "        initialize_weight(self.layer2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, dropout_rate, head_size=4):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.head_size = head_size\n",
    "\n",
    "        self.att_size = att_size = hidden_size // head_size\n",
    "        self.scale = att_size ** -0.5\n",
    "\n",
    "        self.linear_q = nn.Linear(hidden_size, head_size * att_size, bias=False)\n",
    "        self.linear_k = nn.Linear(hidden_size, head_size * att_size, bias=False)\n",
    "        self.linear_v = nn.Linear(hidden_size, head_size * att_size, bias=False)\n",
    "        initialize_weight(self.linear_q)\n",
    "        initialize_weight(self.linear_k)\n",
    "        initialize_weight(self.linear_v)\n",
    "\n",
    "        self.att_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.output_layer = nn.Linear(head_size * att_size, hidden_size,\n",
    "                                      bias=False)\n",
    "        initialize_weight(self.output_layer)\n",
    "\n",
    "    def forward(self, q, k, v, mask, cache=None):\n",
    "        orig_q_size = q.size()\n",
    "\n",
    "        d_k = self.att_size\n",
    "        d_v = self.att_size\n",
    "        batch_size = q.size(0)\n",
    "\n",
    "        # head_i = Attention(Q(W^Q)_i, K(W^K)_i, V(W^V)_i)\n",
    "        q = self.linear_q(q).view(batch_size, -1, self.head_size, d_k)\n",
    "        if cache is not None and 'encdec_k' in cache:\n",
    "            k, v = cache['encdec_k'], cache['encdec_v']\n",
    "        else:\n",
    "            k = self.linear_k(k).view(batch_size, -1, self.head_size, d_k)\n",
    "            v = self.linear_v(v).view(batch_size, -1, self.head_size, d_v)\n",
    "\n",
    "            if cache is not None:\n",
    "                cache['encdec_k'], cache['encdec_v'] = k, v\n",
    "\n",
    "        q = q.transpose(1, 2)                  # [b, h, q_len, d_k]\n",
    "        v = v.transpose(1, 2)                  # [b, h, v_len, d_v]\n",
    "        k = k.transpose(1, 2).transpose(2, 3)  # [b, h, d_k, k_len]\n",
    "\n",
    "        # Scaled Dot-Product Attention.\n",
    "        # Attention(Q, K, V) = softmax((QK^T)/sqrt(d_k))V\n",
    "        q.mul_(self.scale)\n",
    "        x = torch.matmul(q, k)  # [b, h, q_len, k_len]\n",
    "        #x.masked_fill_(mask.unsqueeze(1), -1e9)\n",
    "        x = torch.softmax(x, dim=3)\n",
    "        x = self.att_dropout(x)\n",
    "        x = x.matmul(v)  # [b, h, q_len, attn]\n",
    "\n",
    "        x = x.transpose(1, 2).contiguous()  # [b, q_len, h, attn]\n",
    "        x = x.view(batch_size, -1, self.head_size * d_v)\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        assert x.size() == orig_q_size\n",
    "        return x\n",
    "\n",
    "\n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_size, filter_size, dropout_rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.self_attention_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "        self.self_attention = MultiHeadAttention(hidden_size, dropout_rate)\n",
    "        self.self_attention_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "       # self.enc_dec_attention_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "        #self.enc_dec_attention = MultiHeadAttention(hidden_size, dropout_rate)\n",
    "        #self.enc_dec_attention_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.ffn_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "        self.ffn = FeedForwardNetwork(hidden_size, filter_size, dropout_rate)\n",
    "        self.ffn_dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, self_mask):\n",
    "        y = self.self_attention_norm(x)\n",
    "        y = self.self_attention(y, y, y, self_mask)\n",
    "        y = self.self_attention_dropout(y)\n",
    "        x = x + y\n",
    "\n",
    "       # if enc_output is not None:\n",
    "       #     y = self.enc_dec_attention_norm(x)\n",
    "        #    y = self.enc_dec_attention(y, enc_output, enc_output, i_mask,\n",
    "                                   #    cache)\n",
    "          #  y = self.enc_dec_attention_dropout(y)\n",
    "        #   x = x + y\n",
    "\n",
    "        y = self.ffn_norm(x)\n",
    "        y = self.ffn(y)\n",
    "        y = self.ffn_dropout(y)\n",
    "        x = x + y\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, filter_size, dropout_rate, n_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        decoders = [DecoderLayer(hidden_size, filter_size, dropout_rate)\n",
    "                    for _ in range(n_layers)]\n",
    "        self.layers = nn.ModuleList(decoders)\n",
    "\n",
    "        self.last_norm = nn.LayerNorm(hidden_size, eps=1e-6)\n",
    "\n",
    "    def forward(self, x, self_mask):\n",
    "        decoder_output = x\n",
    "        for i, dec_layer in enumerate(self.layers):\n",
    "            decoder_output = dec_layer(decoder_output,\n",
    "                                       self_mask)\n",
    "        return self.last_norm(decoder_output)\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_layers=6,\n",
    "                 hidden_size=32,\n",
    "                 filter_size=64,\n",
    "                 dropout_rate=0.1,\n",
    "                window_size=32):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.window_size = window_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.emb_scale = hidden_size ** 0.5\n",
    "        \n",
    "        \n",
    "\n",
    "        self.price_embedding = nn.Linear(window_size,hidden_size) # this 1 can be scaled to # of cryptos, trends, etc. Need to fix loaders as well for that but interesting opportunity. \n",
    "        \n",
    "        nn.init.normal_(self.price_embedding.weight, mean=0,\n",
    "                        std=hidden_size**-0.5)\n",
    "        \n",
    "        self.decoder = Decoder(hidden_size, filter_size,\n",
    "                               dropout_rate, n_layers)\n",
    "        \n",
    "        self.output_mlp = FeedForwardNetwork(hidden_size,filter_size,dropout_rate,output_size=1) \n",
    "\n",
    "\n",
    "        # For positional encoding\n",
    "        num_timescales = self.hidden_size // 2\n",
    "        max_timescale = 10000.0\n",
    "        min_timescale = 1.0\n",
    "        log_timescale_increment = (\n",
    "            math.log(float(max_timescale) / float(min_timescale)) /\n",
    "            max(num_timescales - 1, 1))\n",
    "        inv_timescales = min_timescale * torch.exp(\n",
    "            torch.arange(num_timescales, dtype=torch.float32) *\n",
    "            -log_timescale_increment)\n",
    "        self.register_buffer('inv_timescales', inv_timescales)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        self_mask = create_self_mask(self.window_size)\n",
    "        \n",
    "        \n",
    "        x = self.decode(x, self_mask)\n",
    "        \n",
    "        x = self.output_mlp(x[:,-1,:])\n",
    "        return x\n",
    "\n",
    "\n",
    "    def decode(self, x, self_mask):\n",
    "\n",
    "        print(x.shape)\n",
    "      #  x = self.price_embedding(x).unsqueeze(0)\n",
    "      #  print(y.shape)\n",
    "        #x = x[:,0] * torch.eye(self.window_size) # this does not convert to batch size \n",
    "\n",
    "     #   print(x.shape)\n",
    "        x = torch.stack([x[i,:] * torch.eye(x.shape[1]) for i in range(x.shape[0])])\n",
    "        #x = x.unsqueeze(0)\n",
    "        print(x.shape)\n",
    "\n",
    "        x *= self.emb_scale\n",
    "        x += self.get_position_encoding(x)\n",
    "      #  print(x.shape)\n",
    "     #   target_embedded = self.t_emb_dropout(target_embedded)\n",
    "\n",
    "        # decoder\n",
    "        output = self.decoder(x, self_mask)\n",
    "\n",
    "        return output # and take the last token of this.. \n",
    "\n",
    "    def get_position_encoding(self, x):\n",
    "        max_length = x.size()[1]\n",
    "        position = torch.arange(max_length, dtype=torch.float32,\n",
    "                                device=x.device)\n",
    "        scaled_time = position.unsqueeze(1) * self.inv_timescales.unsqueeze(0)\n",
    "        signal = torch.cat([torch.sin(scaled_time), torch.cos(scaled_time)],\n",
    "                           dim=1)\n",
    "        signal = F.pad(signal, (0, 0, 0, self.hidden_size % 2))\n",
    "        signal = signal.view(1, max_length, self.hidden_size)\n",
    "        return signal\n",
    "\n",
    "\n",
    "def create_self_mask(target_len, device=None):\n",
    "    # Prevent leftward information flow in self-attention.\n",
    "    ones = torch.ones(target_len, target_len, dtype=torch.uint8,\n",
    "                      device=device)\n",
    "    t_self_mask = torch.triu(ones, diagonal=1).unsqueeze(0)\n",
    "\n",
    "    return t_self_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what this all looks like, for the future model(s). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from dataloaders import create_dataloaders\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train_loader, _, _ = create_dataloaders(prior_years=8,crypto='bitcoin',values='usd',batch_size=4,buy_thresh=3,labels_to_load=['pct_change'],window=14)\n",
    "\n",
    "for batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(hidden_size=14,window_size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 14])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 14])\n",
      "torch.Size([4, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "out = model.forward( batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9707],\n",
       "        [0.5785],\n",
       "        [0.7585],\n",
       "        [1.1213]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass this output to a little NN, and the rest is history. That'll do. \n",
    "\n",
    "One thought is maybe make the hidden size larger that way days can more effectively occupy separate areas? or do we like the blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Embedding?\n",
    " to use this, I would need all possible integer values this price can take, which is a lot! Instead, we skip the lookup table and transform to a \n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
